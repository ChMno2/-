# 概念
在超啓發式演算法中，區域最佳解(Local optimum)是此領域常遇到的一個問題，
在迭代(iteration)過程中若是陷入區域最佳解，可能導致程式卡在此解，無法跳脫找到更佳的解，
這邊以一個經典的函數最佳化問題來做說明，大家可能會比較好理解。

所謂的區域最佳解就是那些山谷，從地形圖來看就是各種顏色的圈圈，
而我們可以看出中間的位置(藍色)才有較好的解，但若演算法跳脫區域最佳解的能力不佳，
很有可能沒辦法找到中間的區域。

而模擬退火演算法則是會讓程式以一定的機率接受較差的解，以此增加跳脫出區域最佳解的機會。
接下來我們就來看看模擬退火演算法的細節吧!

當我們使用梯度下降演算法來優化目標函數的時候，當越來越接近Loss值的全局最小值時，
學習率應該變得更小來使得模型盡可能接近這一點，而餘弦退火（Cosine annealing）可以透過餘弦函數來降低學習率。
餘弦函數中隨著x的增加餘弦值首先緩慢下降，然後加速下降，再次緩慢下降。
這種下降模式能和學習率配合，以一種十分有效的計算方式來產生很好的效果。
![image](https://github.com/user-attachments/assets/c8b4180a-9ea7-4d72-9b36-382452aa43d9)

# 程式流程

模擬退火演算法的運行流程與爬山演算法大致相同，有以下五步，
一開始先設定退火溫度以及迭代次數(Iteration)，再進行隨機初始化(2)，
接著會不斷的進行TED(3–5)的步驟，直到設定的迭代次數才終止。
為了方便大家了解這邊還是以 One max problem 來進行解說。

1.設定 設定迭代次數(Iteration)、初始溫度(T)和退火係數(Rₜ)。

2.初始化(Initial) 以隨機方式進行初始化，接著再評估該組解的好壞。

以長度10為例
3.Transition 將第一步產生出的解，隨機挑選一個位置進行更動。

橘色位置即為改動位置
4.Evaluation 評估適應值(Fitness value)大小。

5.Determination 將第四步評估出的適應值與先前的進行比較。
若優於或等於先前解則更新。
若無則進行退火環節，退火的進行方式是使用退火溫度(T)和適應值的差值(Δf)計算出允許機率，
接著隨機一個0–1的浮點數(r)，若該隨機值(r)≤允許機率則進行更新。

每次迭代的最後皆需進行降溫動作，會將溫度T乘上一個小於1的數值(Rₜ)，Rₜ的數值大小取決於想要的收斂速度。
![截圖 2024-08-20 下午3 01 11](https://github.com/user-attachments/assets/5870062d-3ae8-49c5-b820-9ccec49b70ed)

* r為一個0–1的隨機浮點數
* Δf為當前的適應值減去先前的適應值
* T則為退火溫度，一般初始值設為1
* 在這邊要注意因為01問題是要找出最大的適應值，所以Δf的計算是當前-先前，若為最小化的問題，Δf的計算要改為先前-當前。

做個小結論，差值越大更新機率越低，隨著迭代進行，更新的次數也會下降，也就是演算法將漸趨收斂。

因為我們的目標最佳化函數可能是多峰的（如下圖），除了全局最優解之外還有多個局部最優解，
在訓練時梯度下降演算法可能陷入局部最小值，此時可以通過突然提高學習率，
來「跳出」局部最小值並找到通往全局最小值的路徑。這種方式稱為帶有重啟的隨機梯度下降方法。
![image](https://github.com/user-attachments/assets/b29201a8-9bf6-40f4-9d6b-72a326ddff05)

餘弦退火的原理
![image](https://github.com/user-attachments/assets/cb80a988-8e9a-4c2c-8d8d-de738fa3eb20)
i 代表第幾次運行（索引值），也就是第幾次重啟。

n_{max}^i 和 n_{min}^i 分別代表在第 i 次運行中的學習率最大值和最小值，定義了學習率的範圍。在某些論文中，提到在每次重啟後，會減少這兩個值以收斂學習率，但也有情況下為了簡化，這兩個值保持不變。

T_{cur} 表示目前執行了多少個 epoch。然而，T_{cur} 在每次 batch 運行後都會更新，這意味著即使一個完整的 epoch 還沒有執行完畢，T_{cur} 的值也會變成小數。例如，若總樣本數為 80，每個 batch 大小為 16，則在一個 epoch 中會有 5 次 batch，當第一個 batch 執行完後，T_{cur} 的值就會更新為 0.2（即 1/5），依此類推。

T_{i} 代表第 i 次運行中總的 epoch 數。在涉及到重啟時，論文中提到為了提高性能，會在一開始設置一個較小的 T_{i}，然後在每次重啟後，T_{i} 會乘以一個 T_{mult} 值來增加。但是，如果不涉及重啟，T_{i} 可以固定為訓練模型的總 epoch 數。



